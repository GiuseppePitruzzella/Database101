# 8. Gestione delle transazioni
## 8.1 Controllo di affidabilità
Il **controllo dell'affidabilità** garantisce due proprietà fondamentali: l'**atomicità** e la **persistenza**. Queste proprietà garantiscono che le transazioni non vengano lasciate incomplete e che gli effetti di ciascuna transazione conclusa con un commit siano mantenuti permanenti.

Il *controllore dell'affidabilità* può svolgere il suo compito mediante il **log**, un *archivio persistente* su cui egli registra le varie azioni svolte dal Dbms. Inoltre, è necessario per il *controllore dell'affidabilità* disporre di **memoria stabile**, cioè di memoria che risulti resistente ai guasti, con probabilità di fallimento prossima allo zero. Quest'ultima è tipicamente realizzata secondo due unità a disco *speculari*, destinate a contenere esattamente la stessa informazione.

Il *controllore dell'affidabilità* è anche responsabile di realizzare le operazioni di ripristino dopo malfunzionamenti, dette *ripresa a caldo* e *ripresa a freddo*.

### 8.1.1 Il log
Descrivendo nuovamente il concetto di *log*, egli è scritto all'interno della *memoria stabile* e contiene infomazioni che permettono di ricostruire il contenuto della base di dati a seguito di guasti.
Il log è formato da **record**, i quali si distinguono in:
- **Record di transazione**;
	- `Begin`, il quale contiene tra parentesi l'identificativo della transazione *T*. Per esempio, $B(T_i)$.
	- `Insert`, il quale contiene tra parentesi l'identificativo della transazione *T*, l'oggetto *O* su cui avviene l'aggiornamento e *AS* (after-state), ossia il valore dell'oggetto *O* successivo alla modifica. Per esempio, $I(T_i, O, AS)$.
	- `Delete`, il quale contiene tra parentesi l'identificativo della transazione *T*, l'oggetto *O* su cui avviene l'aggiornamento ed un valore *BS* (before-state). Per esempio, $D(T_i, O, BS)$.
	- `Update`,  il quale contiene tra parentesi l'identificativo della transazione *T*, l'oggetto *O* su cui avviene l'aggiornamento e due valori *BS* (before-state), ossia il valore dell'oggetto *O* precedente alla modifica, e *AS* (after-state), ossia il valore dell'oggetto *O* successivo alla modifica. Per esempio, $U(T_i, O, BS, AS)$.
	- `Commit`, il quale contiene tra parentesi l'identificativo della transazione *T*. Per esempio, $C(T_i)$.
	- `Abort`,  il quale contiene tra parentesi l'identificativo della transazione *T*. Per esempio, $A(T_i)$.

	I recordi di transazione consentono di disfare e rifare le azioni in un database, rispettivamente chiamate: 
	- `Undo`: attraverso cui è possibile disfare un operazione su un oggetto *O*, ricopiando in *O* il valore *BS*. Nel caso di un insert, viene eliminato l'oggetto *O*.
	- `Redo`: attraverso cui è possibile rifare un operazione su un oggetto *O*, ricopiando in *O* il valore *AS*. Nel caso di una delete, viene eliminato l'oggetto *O*.
	Quest'ultime due operazioni godono di una proprietà essenziale, la $proprietà\;di\;idempotenza$, il che indica che svolgere $n$ volte un operazione di *undo* o *redo* sulla stessa azione, equivale allo svolgimento di tale azione una sola volta.
		$Undo(Undo(A))\,=\,Undo(A)\;\;\;\;\;\;\;\;Redo(Redo(A))\,=\,Redo(A)$
- **Record di sistema**;
	- `Checkpoint`, il quale viene svolta periodicamente dal gestore dell'affidabilità, con l'obiettivo di registrare quali attività sono attive al momento. Un operazione di *checkpoint* si costiuisce dei seguenti passi:
		- Viene sospesa la possibilità di accettare nuove richieste di scrittura, commit o abort, da parte di ogni transazione;
		- Si trasferiscono in memoria di massa tutte le pagine del buffer su cui sono state eseguite modifiche da parte di transazioni che hanno già eseguito il commit;
		- Si scrive in modo sincrono nel log un record di checkpoint che contiene identificatori delle transazioni attive;
		- Si riprende l'accettazione delle operazione sopra sospese.
	Si noti che, eseguita l'operazione di checkpoint, gli effetti delle transazioni che hanno eseguito il commit sono state registrate in modo permanente.
	Per indicare che vi è stato un *checkpoint*, scriveremo nel log: $CK(T_i, T_j)$, con $T_i, T_j$ uguali alle transazioni attive al momento del *checkpoint*.
	
	- `Dump`, il quale consiste in una copia completa e consistente della base di dati, che viene nomalmente effettuata in mutua esclusione con tutte le altre transazioni, quando il sistema non è operativo (per es. durante la notte). 
	La copia viene memorizzata in memoria stabile, ed è conosciuta anche con il nome di *backup*. 
	Per indicare che vi è stato una *dump*, scriveremo nel log: $DUMP$.

### 8.1.2 Gestione dei guasti
Suddividiamo i **possibili guasti** dal punto di vista di un Dbms in due classi:
- **Guasti di sistema**.
	Riguardano tutti guasti indotti da problemi legati al software, per esempio: il sistema operativo o l'interruzione del funzionamento dei dispositivi dovuto ad un calo di tensione.
	I guasti di sistema si traducono nella perdita di contenuto della memoria centrale (quindi, buffer compresi), mantenendo valido il contenuto della memoria di massa (quindi database e log).
- **Guasti di dispositivo**.
	Riguardano tutti i guasti relativi ai dispositivi di gestione della memoria di massa.
	Un guasto di dispositivo si traduce in una perdita del contenuto del database, ma non del log.
Relativamente ai guasti, studiamo il modello di funzionamento di un Dbms chiamato "$fail-stop$". Attraverso questo modello, quando il database nota un guasto, egli forza l'arresto completo delle transazioni ed il successivo ripristino del corretto funzionamento del sistema operativo (*boot*). A questo punto, viene attivata una procedura di ripresa denominata **ripresa a caldo**, nel caso di un guasto di sistema, o una procedura di **ripresa a freddo**, nel caso di un guasto di dispositivo.
Al termine dell'operazione di ripresa, il sistema è nuovamente utilizzabile.

#### Ripresa a caldo
La ripresa a caldo, utilizzata nel caso di guasti di sistema, si compone delle seguenti quattro fasi:
- Ripercorriamo il log all'indietro fino all'ultimo (ossia, il più recente) *checkpoint* avvenuto.
- Costruiamo due insiemi: l'insieme di *UNDO* e l'insieme di *REDO*. Inizialmente l'insieme di *UNDO* sarà formato da tutte le transazioni attive al momento dell'ultimo checkpoint avvenuto, mentre l'insieme di *REDO* sarà inizialmente vuoto. A questo punto, scorriamo in avanti il *log* a partire dall'ultimo *checkpoint* ed aggiungiamo una transazione $T_i$ in UNDO per ogni $B(T_i)$ presente. Inoltre, spostiamo una transazione $T_i$ dall'insieme di UNDO all'insieme di REDO per ogni $C(T_i)$.
- Vengono disfatte tutte le transazioni in UNDO, fino alla transazione più vecchia in UNDO o REDO. 
- Vengono rifatte tutte le operazioni di REDO nell'ordine in cui sono state registrate nel log.

#### Ripresa a freddo
La ripresa a caldo, utilizzata nel caso di guasti di sistema, si compone delle seguenti tre fasi:
- Si accede al dump e si ricopia selettivamente la parte deteriorata della base di dati. Si accede anche al più recente record di dump nel log.
- Si ripercorre in avanti Il log, applicando relativamente alla parte deterioratà della base di dati sia le azioni sulla base di dati sia le azioni di commit o abort e riportandosi cosi nella situazione precedente al guasto.
- Infine, si svolge una [[#Ripresa a caldo|ripresa a caldo]].

## 8.2 Controllo di concorrenza
Un Dbms deve spesso servire diverse applicazioni e rispondere alle richieste provenienti da diversi utenti.
E' necessario, quindi, un controllo di concorrenza, il quale riceve le richieste di accesso ai dati e decide se autorizzarle o meno, eventualmente riordinandole.
Poiché, in pratica, esso stabilisce l'ordine degli accessi, il controllore della concorrenza viene anche chiamato scheduler.

### 8.2.1 Anomalie delle transazioni
L'esecuzione concorrente di varie transazioni può causare alcuni problemi di correttezza, o anomalie, la presenza di queste anomalie motiva la necessita di controllare la concottenza. Vediamo cinque casi tipici di anomalie.
1. **Perdita di aggiornamento**
	Supponiamo di avere due transazioni identiche che operano sullo stesso oggetto $x$ della base di dati.
$$
t_1 = r_1(x), x = x + 1, w_1(x)	\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
t_2 = r_2(x), x = x + 1, x_2(x)
$$
	Denotiamo $r_i(x)$ come la lettura dell'oggetto $x$ da parte della transazione $T_i$. Notiamo cosa succede ipotizzando, per esempio, $x = 2$. 
	Seguendo le operazioni in sequenza (prima $t_1$, poi $t_2$), il valore finale per $x$ sarà uguale a $4$. 
	Lo stesso non si può dire se le due transazioni avvengono secondo la seguente esecuzione concorrente:

	$t_1: r_1(x)$
	$t_1: x = x + 1$

	$t_2: r_2(x)$
	$t_2: x = x + 1$
	$t_2: w_2(x)$
	$t_2: commit$

	$t_1: w_1(x)$
	$t_1: commit$

	In tal caso, il valore finale per $x$ sarà uguale a $3$, il che è un errore. Questa anomalia è nota come *perdita di aggiornamento*, in quanto l'incremento di $t_1$ viene effettivamente perso.

	**TODO**: Controlla definizione *perdita di aggiornamento*.

2. **Lettura sporca**
	Supponiamo di avere due transazioni che operano sullo stesso oggetto $x$ della base di dati.
$$
t_1 = r_1(x), x = x + 1, w_1(x),\;abort	\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
t_2 = r_2(x),\;commit
$$
	Supponiamo che le due transazioni avvengono secondo la seguente esecuzione concorrente:
	
	$t_1: r_1(x)$
	$t_1: x = x + 1$
	$t_1: w_1(x)$
	
	$t_2: r_2(x)$
	$t_2: commit$

	$t_1: abort$

	In tal caso, il valore finale per $x$ sarà uguale a $2$, ma la seconda transazione ha effettivamente letto (e potenzialmente comunicato all'esterno) il valore $3$, un valore mai esistito poichè la transazione è andata in $abort$. Il tutto avviene poichè $T_2$ legge uno stato intermedio di $T_1$ che non avrebbe dovuto vedere. Questa anomalia prende il nome di *lettura sporca*.
	
3. **Letture inconsistenti**
		Supponiamo di avere due transazioni che operano sullo stesso oggetto $x$ della base di dati.
$$
t_1 = r_1(x), r_1(x),\;commit	\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
t_2 = r_2(x), x = x + 1, x_2(x),\;commit
$$
	Supponiamo che le due transazioni avvengono secondo la seguente esecuzione concorrente:

	$t_1: r_1(x)$
	
	$t_2: r_2(x)$
	$t_2: x = x + 1$
	$t_2: w_2(x)$
	$t_2: commit$
	
	$t_1: r_1(x)$
	$t_1: commit$

	In tal caso, $T_1$ legge prima $x = 2$, poi $x = 3$. Il tutto è un errore poichè è opportuno che una transazione che accede due volte allo stesso dato, abbia ritornato lo stesso valore.
	Questa anomalia prende il nome di *lettura inconsistente*.
	
4. **Aggiornamento fantasma**
		Supponiamo di avere due transazioni che operano su tre oggetti diversi $x, y\;e\;z$ della base di dati, tale che $x + y + z = 1000$.
$$
t_1 = r_1(x), r_1(y), r_1(z), s = x + y + z\;commit
$$
$$
t_2 = r_2(y), y = y - 100, r_2(z), z = z + 100, w_2(y), w_2(z)\;commit
$$
	Supponiamo che le due transazioni avvengono secondo la seguente esecuzione concorrente:
	$t_1: r_1(x)$
	
	$t_2: r_2(y)$
	
	$t_1: r_1(y)$
	
	$t_2: y = y - 100$
	$t_2: r_2(z)$
	$t_2: z = z + 100$
	$t_2: w_2(y)$
	$t_2: w_2(z)$
	$t_2: commit$
	
	$t_1: r_1(z)$
	$t_1: s = x + y + z$
	$t_1: commit$

	In tal caso, $s$ di $T_1$, che dovrebbe leggere una somma pari a 1000, legge 1100. Il tutto avviene poichè $t_1$ nota solo in parte i cambiamenti effettuati da $t_2$. 
	Questa anomalia prende il nome di *aggionamento fantasma*.
	
5. **Inserimento fantasma**
	Consideriamo una transazione che valuta un valore aggregato relativo all'insieme di tutti gli elementi che soddisfano un predicato di selezione; per esempio, il voto medio degli studenti del primo anno. 
	Consideriamo il caso in cui tale valore aggregato viene valutato due volte, e tra la prima e la seconda valutazione viene inserito un nuovo studente del primo anno. 
	In tal caso, i due valori medi letti dalla transazione potranno essere differenti; l'anomalia, quindi, si basa sul fatto che vi è una nuova tupla che compare improvvisamente, come uno fantasma.

### 8.2.2 Gestione della concorrenza
Garantire l'isolamento è un operazione che può risultare molto onerosa e per questo i Dbms prevedono la possibilità di specificare un grado di protezione arbitrario per ogni transazione.
Distinguiamo quattro gradi di protezione:
- *read uncommited*, attraverso cui sono permesse le anomalie di lettura sporca, lettura inconsistente, aggiornamento ed inserimento fantasma;
- *read committed*, in cui differentemente dalla fase precedente viene evitata la lettura sporca;
- *repeatable read*, attraverso cui vengono evitate tutte le anomalie a meno dell'inserimento fantasma;
- *serializable*, attraverso cui vengono evitate tutte le anomalie.

### 8.2.3 Teoria del controllo di concorrenza
Definiamo una **transazione** come una sequenza di azioni di lettura o scrittura. Per esempio, una transazione $t_1$ potrebbe essere rappresentata dalla sequenza: $r_0(x)r_1(y)w_1(x)w_1(y)$.
Poichè le transazioni avvengono in modo concorrente, le operazioni per ogni transazione avvengono in istanti differenti. Definiamo, quindi, uno **schedule** come l'ordine in cui le richieste vengono soddisfatte.
Un esempio di schedule è il seguente: $S_1 = r_1(x)\,r_2(z)\,w_1(x)\,w_2(z)$. Si noti che con $r_i(x)$ intendiamo la lettura dell'oggetto $x$ da parte della transazione $t_i$, mentre con $w_j(y)$ intendiamo la scrittura dell'oggetto $y$ da parte della transazione $t_j$.

In questo capitolo ci occuperemo, quindi, di verificare la **correttezza** degli schedule assumendo che le transazioni abbiano un esito noto (commit o abort).
Considerare che tutte e solo le transazioni che terminano con commit indica considerare la **commit-proiezione** per lo schedule.

Definiamo uno **schedule seriale** se le azioni di ciascuna transazione appaiono in sequenza. Un esempio di schedule seriale è il seguente: $S_1 = r_0(x)\,r_0(y)\,w_0(x)\;r_1(y)\,r_1(x)\,w_1(y)\;r_2(x)\,r_2(y)\,r_2(z)\,w_2(z)$.
Si noti, infatti, che in S_1 vengono eseguite prima tutte le azioni relative alla transazione $t_0$, poi $t_1$, poi $t_2$.

Uno schedule $S_i$ è detto **serializzabile** se produce lo stesso effetto di uno schedule seriale $S_j$.

#### View-equivalenza
Per definire la *view-equivalenza* è necessario innanzitutto definire il concetto di:
- $legge-da$. Una lettura $r_i(x)\;legge-da\;w_j(x)$ se $w_j(x)$ precede $r_i(x)$ e non vi è alcun $w_k(x)$ compreso tra i due.
- $scrittura\;finale$. Una scrittura $w_i(x)$ viene detta $finale$ se è l'ultima scrittura per $x$ che appare nello schedule.
A questo punto, possiamo definire il concetto di *view-equivalenza*. Definiamo due schedule $S_i$ ed $S_j$ $view-equivalenti$ se possiedono le stesse $legge-da$ e le stesse $scritture\;finali$. In particolare, se $S_i$ è $view-equivalente$ ad uno schedule seriale $S_j$, allora $S_i$ è detto $view-serializzabile$. Definiamo **VSR** l'insieme di schedule $view-serializzabili$.

E' possibile determinare se è uno schedule è in *VSR* effettuando un confronto delle relazioni *legge-da* e *scritture finali* per ogni transazione. Determinare se uno schedule è *view-equivalente* ad un qualsiasi schedule seriale è un problema $NP-Hard$.


#### Conflict-equivalenza
Per definire la conflict-equivalenza è necessario innanzitutto definire il concetto di $conflitto$.
Definiamo un azione $a_i$ in $conflitto$ con $a_j$, con $i \neq j$, se i due operano sullo stesso oggetto ed *almeno* uno di essi è una scrittura.
A questo punto, possiamo definire il concetto di conflict-equivalenza*. Definiamo due schedule $S_i$ ed $S_j$ $conflict-equivalenti$ se possiedono le stesse operazioni e ogni coppia di operazioni in conflitto è nello stesso ordine nei due schedule.
In particolare, se $S_i$ è $conflict-equivalente$ ad uno schedule seriale $S_j$, allora $S_i$ è detto $conflict-serializzabile$. Definiamo **CSR** l'insieme di schedule $conflict-serializzabili$.
Si noti che $CSR \subseteq VSR$.

E' possibile determinare se è uno schedule è in CSR mediante il suo grafo dei conflitti. Un grafo dei conflitti si compone di un nodo per ogni transazione ed un arco dal nodo $i$ al nodo $j$ se esiste un conflitto tra un azione $a_i$ ed azione $a_j$, tale che $a_i$ precede $a_j$. Uno schedule è in CSR se il suo grafo dei conflitti è aciclico.

#### Locking a due fasi
Poichè entrambi i modelli visti in precedenza hanno delle limitazione dovute alla loro complessità, è necessario trovare un meccanismo che superi quest'ultime limitazioni. Il più noto meccanismo di controllo utilizzato in pratica si basa sul **locking**.
In particolare il concetto si basa su un semplice principio: *proteggere ogni operazione di lettura e scrittura tramite opportune primitive, r_lock e w_lock*.
Per questo motivo, è necessario rispettare i seguenti **vincoli**:
- Ogni azione di lettura deve essere preceduta da un lock in scrittura (**r_lock**) e succeduta da un *unlock*. Il lock utilizzato si dice *condiviso*, poichè su un dato possono essere contemporaneamente condividi più lock di questo tipo.
- Ogni azione di scrittura deve essere preceduta da un lock in scrittura (**w_lock**) e succeduta da un *unlock*. Il lock si dice *esclusivo* poichè non possono coesistere altri lock (esclusivi o condivisi) sullo stesso dato.
Una transazione che segue questi vincoli è detta *ben formata rispetto il locking*.
Si noti che una transazione che deve effettuare sia una lettura che una scrittura può richiedere direttamente un lock in scrittura oppure richiedere un lock in lettura per poi richiederne uno in scrittura.

Il **lock manager** è colui che gestisce tutte le richieste di lock. Quando il lock manager concede un lock per una risorsa, si dice che quest'ultima risorsa viene **acquisita** dalla transazione richiedente; viceversa, la risorsa viene **rilasciata**.
Quando una richiesta di lock non viene concessa, la transazione viene messa in **stato di attesa**.
I lock già concessi vengono memorizzati in una *tabella di lock*.

La politica che viene seguita dal lock-manager per concedere o meno il lock ad una risorsa è rappresentata dalla seguente tabella. Si noti che in ogni cella è rappresentato l'esito della richiesta e, subito dopo la freccia, il valore assunto dopo l'esito.

| Richiesta | Se la risorsa è libera | Se la risorsa è r_locked | Se la risorsa è w_locked |
|--|--|--|--|
|r_lock|OK -> r_locked|OK -> r_locked|NO -> w_locked|
|w_lock|OK -> w_locked|NO -> r_locked|NO -> w_locked|
|unlock|error|OK -> dipende|OK -> libero|

I locking, quindi, sono uno strumento molto utile per garantire che le transazioni lavorino in mutua esclusione. D'altra parte, per avere la garanzia che le transazioni seguano uno schedule serializzabile è necessario porre una nuova restrizione sull'ordinamento
 delle richieste di lock. Quest'ultima viene riassunta con il nome di **2PL**, ovvero *two-phases-locking*, il quale si basa sul seguente concetto: una transazione, dopo aver rilasciato un lock, non possono acquisirne altri. 
 La classe **2PL** contiene tutti gli schedule che soddisfano questa condizione. Inoltre, $2PL \subseteq CSR$.

 Notiamo che 2PL ci aiuta nella risoluzione della maggior parte delle anomalie. D'altra parte per risolvere anomalie come la lettura sporca dobbbiamo, ancora una volta, porre nuove limitazioni. Consideriamo quindi una restrizione di 2PL, ossia **2PL stretto**.
 Il 2PL stretto si basa sul seguente concetto: *i lock di una transazione possono essere rilasciati solo dopo aver correttamente effettuato le operazioni di commit/abort*.
 
 [*NB*] Relativamente all'anomalia "*inserimento fantasma*", accenniamo solo al fatto che una sua risoluzione si basa sul concetto di "*lock di predicato*".